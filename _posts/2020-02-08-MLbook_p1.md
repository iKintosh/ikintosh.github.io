# Читаю "Прикладное машинное обучение с помощью Scikit-Learn и TensorFlow". Часть 1

Нужно участвовать в каггл соревнованиях, чтобы отработать пайплайн: исследование данных — очистка данных — подготовка данных
— эксперимент с мл моделями — повторить.

Писать свои кастомные обработчики данных лучше в едином интерфейсе. И в принципе ничего выдумывать тут не надо, 
тк sklearn имеет довольно удобный и понятный интерфейс для обработчиков данных: `fit()`, `transform()`, `fit_transform()`. 
Это делает их понятными, переиспользуемыми и даже можно запихивать в структуры sklearn (`pipeline`). 
Можно даже наследоваться от специальных методов, чтобы еще больше сблизить свои методы с sklearn. 

Аналогично с кастомными моделями: `fit()`, `predict()`. Просто и понятно для использования.

> Да и вообще можно составлять структуры (классы), для которых выбор и генерация признаков и обучение модели 
будет являться гиперпараметром (главное, чтобы у класса были методы fit и predict) и потом запускать оптимайзер 
(GridSearchCV, Optuna, Hyperopt, etc).

Любую модель, которая получается во время экспериментов следует сохранять (как минимум сохранять информацию о данных, 
которые использовались для обучения, и гиперпараметры модели).

Класс CategoricalEncoder превращает категориальную фичу в бинарный вектор.

**(ВОТ ЭТО НЕЛЬЗЯ ОТРАБОТАТЬ НА КАГГЛ СОРЕВНОВАНИЯХ)** 

Если вдруг модель идет в прод, то что нужно сделать:

- Написать тесты к кастомным обработчикам данных
- Написать тесты ко всему пайплайну обработки данных
- Написать Minimum Value тесты к модели МЛ (например, что метрика на данных выше заданной или выше, чем у какой-то базовой модели) 
(Идеально, если можно считать метрики на новых данных, в противном случае придется искать какие-то обходные пути оценки модели, 
что может быть сложно)
- Написать тесты на входные данные, чтобы мониторить их качество (ЭТО МОЖЕТ БЫТЬ ИЗЛИШНИМ ШАГОМ, особенно, 
если неясно, как оценивать качество данных)
- В идеале, ко всему этому делу стоит прикрутить оповещения, чтобы знать, что что-то идет не так
