# Немного про autoML и NAS

## Прочитал цикл статей на [fast.ai](fast.ai) о autoML и стоит ли его бояться.

[Часть 1](https://www.fast.ai/2018/07/12/auto-ml-1/)

В первой статье Рейчел Томас говорит о том, что построение продуктов основанных на данных это очень сложный процесс, 
построение моделей, в котором — один из многих этапов. Всего выделяется пять этапов: 

- Понимание бизнес-процесса и задачи
- Работа с источниками данных и процесс сбора данных
- Создание модели ← вот тут сидит autoML
- Вывод модели в продакшен
- Мониторинг итогового пайплайна

Самыми сложными и времязатратными частями этого процесса авторка называет пункты 2 и 3. И только пункт 3, возможно, 
можно адекватно оптимизировать. И это неплохо по своей сути...

[Часть 2](https://www.fast.ai/2018/07/16/auto-ml2/) и [Часть 3](https://www.fast.ai/2018/07/23/auto-ml-3/)

Далее Рейчел более подробно рассказывает, что пусть autoML и может помочь в выборе модели, гиперпараметров и даже построении фичей, 
то подготовка данных является равноценно важным шагом от которого никак нельзя избавиться. 

Далее фокус переносится на конкретный метод autoML: neural architecture search. NAS — это метод поиска новой архитектуры нейронной 
сети для решения поставленной задачи. Основная проблема данного метода, по мнению Рейчел, в том, что этот метод требует огромных 
вычислительных ресурсов. Хотя упоминаются исследования, которые пытаются сократить необходимость с тысяч GPU часов до сотен. 
Тем не менее, нет никаких доказательств, что для решения различных задач под каждую задачу следует строить свою архитектуру 
нейронной сети. К тому же этот подход делает невозможным использование transfer learning.

Рейчел считает, что хорошим решением будет не использование NAS методов для каждой задачи, а использование существующих 
предобученных сетей и методов, которые могут настроить гиперпараметры. Причем, индустрию интересуют методы, которые проще 
использовать под каждую новую задачу, так что исследование методов подбора гиперпараметров или создание моделей с меньшим 
их количеством будет более востребовано, чем идея запуска NAS на сотнях GPU на несколько недель.
