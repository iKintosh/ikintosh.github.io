# Прочитал "Как решить 90% задач NLP"

[Оригинал](https://habr.com/ru/company/oleg-bunin/blog/352614/)

Key points:
1. Собрать достаточно данных. Это проще, чем пытаться придумать алгоритм, который будет работать на маленьком наборе данных
2. Очистить данные
	- Удалить цифры, URLы, смайлы и другие символы, которые алгоритмы не смогут переварить
	- Привести весь текст к нижнему регистру (если только дальнейшая обработка не требует обратного, например, выделение сущностей)
	- Исправить ошибки в написании слов (если требуется, иначе просто выкинуть эти слова)
	- Лемматизировать (довольно дорогая операция)
3. Привести к полученные документы к представлению слов (от простого к сложному)
	- One-hot encoding
	- TF-IDF
	- Word2Vec
	- etc.
4. Визуализировать датасет. Посмотреть как разделяются классы (обычно, плохо)
5. Обучить классификатор
	- Линейная регрессия
	- Случайный лес
	- SVM
	- Нейронные сети
		- Dense
		- RNN
		- Conv
6. Провалидировать классификатор
	- Матрица ошибок
	- Интерпретация

_Есть некоторое ощущение, что между 2 и 4 пунктом есть еще несколько, которые относятся к EDA, но прямо сейчас не могу придумать_